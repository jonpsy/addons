{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "average_optimizers_callback.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# Model Averaging\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/average_optimizers_callback\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/average_optimizers_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/addons/blob/master/docs/tutorials/average_optimizers_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "      <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/addons/docs/tutorials/average_optimizers_callback.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use Moving Average Optimizer along with the Model Average Checkpoint from tensorflow addons pagkage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2UNySlpXkbl"
   },
   "source": [
    "## Moving Averaging \n",
    "\n",
    "> The advantage of Moving Averaging is that they are less prone to rampant loss shifts or irregular data representation in the latest batch. It gives a smooothened and a more genral idea of the model training until some point.\n",
    "\n",
    "## Stochastic Averaging\n",
    "\n",
    "> Stochastic Weight Averaging converges to wider optimas. By doing so, it resembles geometric ensembeling. SWA is a simple method to improve model performance when used as a wrapper around other optimizers and averaging results from different points of trajectory of the inner optimizer.\n",
    "\n",
    "## Model Average Checkpoint \n",
    "\n",
    "> `callbacks.ModelCheckpoint` doesn't give you the option to save moving average weights in the middle of training, which is why Model Average Optimizers required a custom callback. Using the ```update_weights``` parameter, ```ModelAverageCheckpoint``` allows you to:\n",
    "1.   Assign the moving average weights to the model, and save them.\n",
    "2.   Keep the old non-averaged weights, but the saved model uses the average weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sXEOqj5cIgyW"
   },
   "source": [
    "!pip install -U tensorflow-addons"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IqR2PQG4ZaZ0"
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4hnJ2rDpI38-"
   },
   "source": [
    "import numpy as np\n",
    "import os"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iox_HZNNYLEB"
   },
   "source": [
    "## Build Model "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KtylpxOmceaC"
   },
   "source": [
    "def create_model(opt):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),                         \n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwdM2pl3RSPb"
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mMOeXVmbdilM"
   },
   "source": [
    "#Load Fashion MNIST dataset\n",
    "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "images, labels = train\n",
    "images = images/255.0\n",
    "labels = labels.astype(np.int32)\n",
    "\n",
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
    "\n",
    "test_images, test_labels = test"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MnAkaTTsLTkW"
   },
   "source": [
    "images.shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEbhI_eajpJe"
   },
   "source": [
    "The dataset provides 60k examples, since the batchsize is set as 32, the optimizer will perform 1875 steps.\n",
    "\n",
    "The goal will be to comparing three optimizers:\n",
    "\n",
    "*   Unwrapped SGD\n",
    "\n",
    "This is the traditional SGD Optimizer. The learning rate is set as 0.01.\n",
    "\n",
    "*   SGD with Moving Average\n",
    "\n",
    "This wrapper computes the moving averages of the weights over the steps. We will use default params here.\n",
    "\n",
    "*   SGD with Stochastic Weight Averaging\n",
    "\n",
    "We will begin the process of cyclic averaging from step 1000 with a period of 50.\n",
    "\n",
    "And see how they perform with the same model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_Q76K1fNk7Va"
   },
   "source": [
    "#Optimizers \n",
    "sgd = tf.keras.optimizers.SGD(0.01)\n",
    "moving_avg_sgd = tfa.optimizers.MovingAverage(sgd)\n",
    "stocastic_avg_sgd = tfa.optimizers.SWA(sgd, 1000, 50)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXlMX4p9qHwg"
   },
   "source": [
    "Both ```MovingAverage``` and ```StochasticAverage``` optimers use ```ModelAverageCheckpoint```."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SnvZjt34qEHY"
   },
   "source": [
    "#Setup the directories for each type of optimizer.\n",
    "vanilla_checkpoint_path = \"training/vanilla/cp-{epoch:04d}.ckpt\"\n",
    "vanilla_checkpoint_dir = os.path.dirname(vanilla_checkpoint_path)\n",
    "\n",
    "ma_checkpoint_path = \"training/ma/cp-{epoch:04d}.ckpt\"\n",
    "ma_checkpoint_dir = os.path.dirname(ma_checkpoint_path)\n",
    "\n",
    "swa_checkpoint_path = \"training/swa/cp-{epoch:04d}.ckpt\"\n",
    "swa_checkpoint_dir = os.path.dirname(swa_checkpoint_path)\n",
    "\n",
    "#Setup the callbacks for each type of optimizer.\n",
    "vanilla_callback = tf.keras.callbacks.ModelCheckpoint(filepath=vanilla_checkpoint_path,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      verbose=1)\n",
    "ma_callback = tfa.callbacks.AverageModelCheckpoint(filepath=ma_checkpoint_path,\n",
    "                                                    update_weights=True)\n",
    "\n",
    "swa_callback = tfa.callbacks.AverageModelCheckpoint(filepath=swa_checkpoint_path,\n",
    "                                                    update_weights=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uabQmjMtRtzs"
   },
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPmifETHmPix"
   },
   "source": [
    "### Vanilla SGD Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xy8W4LYppadJ"
   },
   "source": [
    "#Build Model\n",
    "model = create_model(sgd)\n",
    "\n",
    "#Train the network\n",
    "model.fit(fmnist_train_ds, epochs=5, callbacks=[vanilla_callback])\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(vanilla_checkpoint_path.format(epoch=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zUpDn4xNI5o5"
   },
   "source": [
    "#Load latest weights\n",
    "latest = tf.train.latest_checkpoint(vanilla_checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uU2iQ6HAZ6-E"
   },
   "source": [
    "#Evalute results\n",
    "model.load_weights(latest)\n",
    "loss, accuracy = model.evaluate(test_images, test_labels, batch_size=32, verbose=2)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAvhD4unmc6W"
   },
   "source": [
    "### Moving Average SGD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "--NIjBp-mhVb"
   },
   "source": [
    "#Build Model\n",
    "model = create_model(moving_avg_sgd)\n",
    "\n",
    "#Train the network\n",
    "model.fit(fmnist_train_ds, epochs=5, callbacks=[ma_callback])\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(ma_checkpoint_path.format(epoch=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TvbZRi_uJ4gs"
   },
   "source": [
    "#Load latest weights\n",
    "latest = tf.train.latest_checkpoint(ma_checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zRAym9EBmnW9"
   },
   "source": [
    "#Evalute results\n",
    "model.load_weights(latest)\n",
    "loss, accuracy = model.evaluate(test_images, test_labels, batch_size=32, verbose=2)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K98lbU07m_Bk"
   },
   "source": [
    "### Stochastic Weight Average SGD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ia7ALKefnXWQ"
   },
   "source": [
    "#Build Model\n",
    "model = create_model(stochastic_avg_sgd)\n",
    "\n",
    "#Train the network\n",
    "model.fit(fmnist_train_ds, epochs=5, callbacks=[swa_callback])\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(swa_checkpoint_path.format(epoch=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CZbkWKouKbRE"
   },
   "source": [
    "#Load latest weights\n",
    "latest = tf.train.latest_checkpoint(swa_checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EOT2E9NBoeHI"
   },
   "source": [
    "#Evalute results\n",
    "model.load_weights(latest)\n",
    "loss, accuracy = model.evaluate(test_images, test_labels, batch_size=32, verbose=2)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhkZ4macL1-J"
   },
   "source": [
    "The observations yields that Stochastic Weight Averaging tends to perform poorly in train loss compared to vanilla SGD but outperforms in test loss."
   ]
  }
 ]
}